"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[2090],{42622:function(e,t,n){n.d(t,{$Sz:function(){return AutoModel},DcG:function(){return AutoModelForDocumentQuestionAnswering},ENH:function(){return AutoModelForCTC},En$:function(){return AutoModelForImageClassification},Hqk:function(){return AutoModelForCausalLM},K2m:function(){return AutoModelForAudioClassification},Kf0:function(){return AutoModelForSeq2SeqLM},OjJ:function(){return AutoModelForTokenClassification},U$$:function(){return AutoModelForImageSegmentation},Zn:function(){return AutoModelForObjectDetection},hZO:function(){return AutoModelForSpeechSeq2Seq},lbf:function(){return AutoModelForTextToSpectrogram},o$X:function(){return AutoModelForSequenceClassification},t78:function(){return AutoModelForMaskedLM},tLj:function(){return AutoModelForVision2Seq},wiU:function(){return AutoModelForQuestionAnswering}});var s=n(3675),r=n(59346),o=n(5261),a=n(97082),i=n(64e3),d=n(71328),l=n(15110);let{InferenceSession:c,Tensor:u}=d.ONNX,_={EncoderOnly:0,EncoderDecoder:1,Seq2Seq:2,Vision2Seq:3,DecoderOnly:4},h=new Map,m=new Map,M=new Map;async function constructSession(e,t,n){let s=`onnx/${t}${n.quantized?"_quantized":""}.onnx`,r=await (0,o.st)(e,s,!0,n);try{return await c.create(r,{executionProviders:d.p})}catch(e){if(1===d.p.length&&"wasm"===d.p[0])throw e;return console.warn(e),console.warn("Something went wrong during model construction (most likely a missing operation). Using `wasm` as a fallback. "),await c.create(r,{executionProviders:["wasm"]})}}async function validateInputs(e,t){let n={},s=[];for(let r of e.inputNames)void 0===t[r]?s.push(r):n[r]=t[r];if(s.length>0)throw Error(`An error occurred during model execution: "Missing the following inputs: ${s.join(", ")}.`);let r=Object.keys(t).length,o=e.inputNames.length;if(r>o){let n=Object.keys(t).filter(t=>!e.inputNames.includes(t));console.warn(`WARNING: Too many inputs were provided (${r} > ${o}). The following inputs will be ignored: "${n.join(", ")}".`)}return n}async function sessionRun(e,t){let n=await validateInputs(e,t);try{let t=await e.run(n);return t=function replaceTensors(e){for(let t in e)e[t]instanceof u?e[t]=new i.es(e[t]):"object"==typeof e[t]&&replaceTensors(e[t]);return e}(t)}catch(e){throw console.error(`An error occurred during model execution: "${e}".`),console.error("Inputs given to model:",n),e}}function prepareAttentionMask(e,t){let n=e.config.pad_token_id??null,s=e.config.eos_token_id??null;(0,r.Wy)(s)&&(s=[s]);let o=-1!==t.indexOf(n),a=null===s||!s.includes(n);if(!o||!a)return(0,i.r6)(t);{let e=BigInt64Array.from(t.data.map(e=>e!=n));return new i.es("int64",e,t.dims)}}function boolTensor(e){return new i.es("bool",[e],[1])}async function seq2seqForward(e,t){let{encoder_outputs:n,past_key_values:s}=t;n||(n=(await encoderForward(e,t)).last_hidden_state);let r={input_ids:t.decoder_input_ids,encoder_hidden_states:n,use_cache_branch:boolTensor(!!s)};e.decoder_merged_session.inputNames.includes("encoder_attention_mask")&&(r.encoder_attention_mask=t.attention_mask),e.addPastKeyValues(r,s);let o=await sessionRun(e.decoder_merged_session,r),a=o.logits;s=e.getPastKeyValues(o,s);let i=e.getAttentions(o);return new Seq2SeqLMOutput({logits:a,past_key_values:s,encoder_outputs:n,...i})}function seq2seqStartBeams(e,t,n,s){let r=[],o=0,a=e.requires_attention_mask??!0,d=n.decoder_input_ids??n.decoder_start_token_id??n.bos_token_id??n.eos_token_id;for(let n of(d instanceof i.es?d=d.tolist().flat():Array.isArray(d)||(d=[d]),t)){n.dims=[1,...n.dims];let t={inputs:n,encoder_outputs:null,prev_model_outputs:null,output_token_ids:d,done:!1,score:0,id:o++};a&&(t.attention_mask=prepareAttentionMask(e,n)),r.push(t)}return r}async function seq2seqRunBeam(e,t){let n=e.main_input_name,s=t.output_token_ids;t.prev_model_outputs&&(s=s.slice(-1));let r={[n]:t.inputs,decoder_input_ids:function(e){if(e instanceof i.es)return e;if(0===e.length)throw Error("items must be non-empty");if(!Array.isArray(e[0]))return new i.es("int64",BigInt64Array.from(e.map(e=>BigInt(e))),[1,e.length]);if(e.some(t=>t.length!==e[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new i.es("int64",BigInt64Array.from(e.flat().map(e=>BigInt(e))),[e.length,e[0].length])}(s),encoder_outputs:t.encoder_outputs,past_key_values:t.prev_model_outputs?.past_key_values};t.attention_mask&&(r.attention_mask=t.attention_mask);let o=await e.forward(r);return t.prev_model_outputs=o,t.encoder_outputs=o.encoder_outputs,o}function seq2seqUpdatebeam(e,t){e.output_token_ids=[...e.output_token_ids,t]}async function encoderForward(e,t){let n={};for(let s of e.session.inputNames)n[s]=t[s];return await sessionRun(e.session,n)}async function decoderForward(e,t){let{input_ids:n,past_key_values:s,attention_mask:r}=t,o={input_ids:n,attention_mask:r??prepareAttentionMask(e,n),use_cache_branch:boolTensor(!!s)};e.addPastKeyValues(o,s);let a=await sessionRun(e.session,o);return{logits:a.logits,past_key_values:s=e.getPastKeyValues(a,s)}}function decoderStartBeams(e,t,n,s,r){let o=[],a=0;for(let n of t){let t,i=n.tolist().map(Number);n.dims=[1,...n.dims],r?(t=r[a]).dims=[1,...t.dims]:t=prepareAttentionMask(e,n);let d={input:n,model_input_ids:n,attention_mask:t,prev_model_outputs:null,output_token_ids:i,num_output_tokens:s,done:!1,score:0,id:a++};o.push(d)}return o}async function decoderRunBeam(e,t){let n=new BigInt64Array(t.output_token_ids.length).fill(1n),s={input_ids:t.model_input_ids,attention_mask:new i.es("int64",n,[1,n.length]),past_key_values:t.prev_model_outputs?.past_key_values},r=await e.forward(s);return t.prev_model_outputs=r,r}function decoderUpdatebeam(e,t){e.output_token_ids=[...e.output_token_ids,t],e.model_input_ids=new i.es("int64",[BigInt(t)],[1,1])}let PreTrainedModel=class PreTrainedModel extends r.Ag{main_input_name="input_ids";constructor(e,t){super(),this.config=e,this.session=t;let n=M.get(this.constructor),s=h.get(n);this.can_generate=!1,this._runBeam=null,this._getStartBeams=null,this._updateBeam=null,this._forward=null,s===_.DecoderOnly?(this.can_generate=!0,this._runBeam=decoderRunBeam,this._getStartBeams=decoderStartBeams,this._updateBeam=decoderUpdatebeam,this._forward=decoderForward):s===_.Seq2Seq||s===_.Vision2Seq?(this.can_generate=!0,this._runBeam=seq2seqRunBeam,this._getStartBeams=seq2seqStartBeams,this._updateBeam=seq2seqUpdatebeam,this._forward=seq2seqForward):(_.EncoderDecoder,this._forward=encoderForward)}async dispose(){let e=[];for(let t of Object.keys(this)){let n=this[t];n instanceof c&&e.push(n.handler.dispose())}return await Promise.all(e)}static async from_pretrained(e,{quantized:t=!0,progress_callback:n=null,config:r=null,cache_dir:a=null,local_files_only:i=!1,revision:d="main",model_file_name:l=null}={}){let c,u={quantized:t,progress_callback:n,config:r,cache_dir:a,local_files_only:i,revision:d,model_file_name:l},m=M.get(this),p=h.get(m);return p===_.DecoderOnly?c=await Promise.all([s.z.from_pretrained(e,u),constructSession(e,u.model_file_name??"decoder_model_merged",u),(0,o.yM)(e,"generation_config.json",!1,u)]):p===_.Seq2Seq||p===_.Vision2Seq?c=await Promise.all([s.z.from_pretrained(e,u),constructSession(e,"encoder_model",u),constructSession(e,"decoder_model_merged",u),(0,o.yM)(e,"generation_config.json",!1,u)]):p===_.EncoderDecoder?c=await Promise.all([s.z.from_pretrained(e,u),constructSession(e,"encoder_model",u),constructSession(e,"decoder_model_merged",u)]):(p!==_.EncoderOnly&&console.warn(`Model type for '${m}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`),c=await Promise.all([s.z.from_pretrained(e,u),constructSession(e,u.model_file_name??"model",u)])),new this(...c)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}_get_logits_processor(e,t,n=null){let s=new a.Jm;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&s.push(new a.Jj(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&s.push(new a.jF(e.no_repeat_ngram_size)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&s.push(new a.ez(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&s.push(new a.CJ(t,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&s.push(new a.C9(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&s.push(new a.dZ(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let n=t>1||null===e.forced_bos_token_id?t:t+1;null!==e.forced_decoder_ids&&(n+=e.forced_decoder_ids[e.forced_decoder_ids.length-1][0]),s.push(new a.GU(e.begin_suppress_tokens,n))}return null!==e.forced_decoder_ids&&s.push(new a.E(e.forced_decoder_ids)),null!==n&&s.extend(n),s}_get_generation_config(e){let t=new a.aP(this.config);return"generation_config"in this&&Object.assign(t,this.generation_config),null!==e&&Object.assign(t,e),t}async generate(e,t=null,n=null,{inputs_attention_mask:s=null}={}){let o;if(!this.can_generate){let e=M.get(this.constructor),t=`The current model class (${e}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`,n=this.config.model_type,s=b.get(n)??x.get(n)??P.get(n)??C.get(n);throw s&&(t+=` Please use the following class instead: '${s[0]}'`),Error(t)}if(!(e instanceof i.es)&&!(0,r.fU)(e)&&!Array.isArray(e))throw Error(`\`inputs\` must be a Tensor, TypedArray, or Array, but is "${e.constructor.name}".`);if(this.config.is_encoder_decoder)o=0;else if(0===(o=e instanceof i.es?e.dims.at(-1):e.length))throw Error("Must supply a non-empty array of input token ids.");t=this._get_generation_config(t),n=n??new a.Jm,n=this._get_logits_processor(t,o,n);let d=t.eos_token_id;null===d||Array.isArray(d)||(d=[d]);let l=1,c=l+(t.max_new_tokens??1/0),u=Number.isInteger(t.max_length)&&(t.max_new_tokens??null)===null,_=a.Z4.getSampler(t),h=this.getStartBeams(e,t,l,s);for(;h.some(e=>!e.done)&&l<c;){let e=[];for(let s of h){if(s.done){e.push(s);continue}if(u&&s.output_token_ids.length>=t.max_length){s.done=!0,e.push(s);continue}let r=await this.runBeam(s);t.output_attentions&&this.addAttentionsToBeam(s,r),t.output_scores;let o=r.logits.slice(null,-1,null);for(let[t,r]of(n(s.output_token_ids,o),_(o))){let n={...s};this.updateBeam(n,t),n.score+=r,d&&d.includes(t)&&(n.done=!0),e.push(n)}}++l,h=(e=this.groupBeams(e).map(e=>e.sort((e,t)=>t.score-e.score).slice(0,t.num_beams))).flat(),t.callback_function&&t.callback_function(h)}let m=this.groupBeams(h),getFlattened=e=>m.map(n=>t.num_return_sequences>1?n.slice(0,t.num_return_sequences).map(t=>t[e]):[n[0][e]]).flat(),p=getFlattened("output_token_ids");if(!t.return_dict_in_generate)return p;{let e=getFlattened("decoder_attentions"),t=getFlattened("cross_attentions");return{sequences:p,decoder_attentions:e,cross_attentions:t}}}addAttentionsToBeam(e,t){if(this.config.is_encoder_decoder){if(!t.cross_attentions||0===t.cross_attentions.length)throw Error("`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.cross_attentions||(e.cross_attentions=[]),e.cross_attentions.push(t.cross_attentions)}if(!t.decoder_attentions||0===t.decoder_attentions.length)throw Error("`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.decoder_attentions||(e.decoder_attentions=[]),e.decoder_attentions.push(t.decoder_attentions)}groupBeams(e){let t=Object.create(null);for(let n of e)void 0===t[n.id]?t[n.id]=[n]:t[n.id].push(n);return Object.values(t)}getPastKeyValues(e,t){let n=Object.create(null);for(let s in e)if(s.startsWith("present")){let r=s.replace("present","past_key_values");t&&s.includes("encoder")?n[r]=t[r]:n[r]=e[s]}return n}getAttentions(e){let t=Object.create(null);for(let n of["cross_attentions","decoder_attentions"]){let s=[];for(let t in e)if(t.startsWith(n)){let n=t.split(".").pop();s[n]=e[t]}t[n]=s}return t}addPastKeyValues(e,t){if(t)Object.assign(e,t);else if(this.config.is_encoder_decoder&&(this.add_encoder_pkv??!0)){let t=[1,this.num_encoder_heads,0,this.encoder_dim_kv],n=[1,this.num_decoder_heads,0,this.decoder_dim_kv];for(let s=0;s<this.num_decoder_layers;++s)e[`past_key_values.${s}.encoder.key`]=new i.es("float32",[],t),e[`past_key_values.${s}.encoder.value`]=new i.es("float32",[],t),e[`past_key_values.${s}.decoder.key`]=new i.es("float32",[],n),e[`past_key_values.${s}.decoder.value`]=new i.es("float32",[],n)}else if(this.config.multi_query){let t=[1,0,2*this.dim_kv];for(let n=0;n<this.num_layers;++n)e[`past_key_values.${n}.key_value`]=new i.es("float32",[],t)}else if("bloom"===this.config.model_type){let t=[1*this.num_heads,this.dim_kv,0],n=[1*this.num_heads,0,this.dim_kv];for(let s=0;s<this.num_layers;++s)e[`past_key_values.${s}.key`]=new i.es("float32",[],t),e[`past_key_values.${s}.value`]=new i.es("float32",[],n)}else{let t=[1,this.num_heads,0,this.dim_kv];for(let n=0;n<this.num_layers;++n)e[`past_key_values.${n}.key`]=new i.es("float32",[],t),e[`past_key_values.${n}.value`]=new i.es("float32",[],t)}}getStartBeams(e,t,n,s){return this._getStartBeams(this,e,t,n,s)}async runBeam(e){return await this._runBeam(this,e)}updateBeam(e,t){return this._updateBeam(e,t)}};let ModelOutput=class ModelOutput{};let BertPreTrainedModel=class BertPreTrainedModel extends PreTrainedModel{};let CamembertPreTrainedModel=class CamembertPreTrainedModel extends PreTrainedModel{};let DebertaPreTrainedModel=class DebertaPreTrainedModel extends PreTrainedModel{};let DebertaV2PreTrainedModel=class DebertaV2PreTrainedModel extends PreTrainedModel{};let DistilBertPreTrainedModel=class DistilBertPreTrainedModel extends PreTrainedModel{};let MobileBertPreTrainedModel=class MobileBertPreTrainedModel extends PreTrainedModel{};let MPNetPreTrainedModel=class MPNetPreTrainedModel extends PreTrainedModel{};let SqueezeBertPreTrainedModel=class SqueezeBertPreTrainedModel extends PreTrainedModel{};let AlbertPreTrainedModel=class AlbertPreTrainedModel extends PreTrainedModel{};let T5PreTrainedModel=class T5PreTrainedModel extends PreTrainedModel{};let LongT5PreTrainedModel=class LongT5PreTrainedModel extends PreTrainedModel{};let MT5PreTrainedModel=class MT5PreTrainedModel extends PreTrainedModel{};let BartPretrainedModel=class BartPretrainedModel extends PreTrainedModel{};let MBartPreTrainedModel=class MBartPreTrainedModel extends PreTrainedModel{};let BlenderbotPreTrainedModel=class BlenderbotPreTrainedModel extends PreTrainedModel{};let BlenderbotSmallPreTrainedModel=class BlenderbotSmallPreTrainedModel extends PreTrainedModel{};let RobertaPreTrainedModel=class RobertaPreTrainedModel extends PreTrainedModel{};let XLMPreTrainedModel=class XLMPreTrainedModel extends PreTrainedModel{};let XLMRobertaPreTrainedModel=class XLMRobertaPreTrainedModel extends PreTrainedModel{};let WhisperPreTrainedModel=class WhisperPreTrainedModel extends PreTrainedModel{};let VisionEncoderDecoderModel=class VisionEncoderDecoderModel extends PreTrainedModel{main_input_name="pixel_values";constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s;let r=this.config.encoder,o=this.config.decoder,a=r.model_type,i=p.get(a)??f.get(a);i||console.warn(`Model type for encoder '${a}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);let d=b.get(o.model_type);if(!d)throw Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`);let l=d[1],c=new l(o,n,s);this.add_encoder_pkv="num_decoder_layers"in c,this.add_encoder_pkv?(this.num_decoder_layers=c.num_decoder_layers,this.num_decoder_heads=c.num_decoder_heads,this.decoder_dim_kv=c.decoder_dim_kv,this.num_encoder_layers=c.num_encoder_layers,this.num_encoder_heads=c.num_encoder_heads,this.encoder_dim_kv=c.encoder_dim_kv):(this.num_layers=c.num_layers,this.num_heads=c.num_heads,this.dim_kv=c.dim_kv)}};let CLIPPreTrainedModel=class CLIPPreTrainedModel extends PreTrainedModel{};let GPT2PreTrainedModel=class GPT2PreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};let GPTNeoPreTrainedModel=class GPTNeoPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_heads,this.num_layers=this.config.num_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};let GPTNeoXPreTrainedModel=class GPTNeoXPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};let GPTJPreTrainedModel=class GPTJPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};let GPTBigCodePreTrainedModel=class GPTBigCodePreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};let CodeGenPreTrainedModel=class CodeGenPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};let LlamaPreTrainedModel=class LlamaPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};let BloomPreTrainedModel=class BloomPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.hidden_size/this.num_heads}};let MptPreTrainedModel=class MptPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_heads,this.num_layers=this.config.n_layers,this.dim_kv=this.config.d_model/this.num_heads}};let OPTPreTrainedModel=class OPTPreTrainedModel extends PreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};let ViTPreTrainedModel=class ViTPreTrainedModel extends PreTrainedModel{};let MobileViTPreTrainedModel=class MobileViTPreTrainedModel extends PreTrainedModel{};let BeitPreTrainedModel=class BeitPreTrainedModel extends PreTrainedModel{};let DetrPreTrainedModel=class DetrPreTrainedModel extends PreTrainedModel{};let DetrObjectDetectionOutput=class DetrObjectDetectionOutput extends ModelOutput{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}};let DetrSegmentationOutput=class DetrSegmentationOutput extends ModelOutput{constructor({logits:e,pred_boxes:t,pred_masks:n}){super(),this.logits=e,this.pred_boxes=t,this.pred_masks=n}};let DeiTPreTrainedModel=class DeiTPreTrainedModel extends PreTrainedModel{};let ResNetPreTrainedModel=class ResNetPreTrainedModel extends PreTrainedModel{};let SwinPreTrainedModel=class SwinPreTrainedModel extends PreTrainedModel{};let DonutSwinPreTrainedModel=class DonutSwinPreTrainedModel extends PreTrainedModel{};let YolosPreTrainedModel=class YolosPreTrainedModel extends PreTrainedModel{};let YolosObjectDetectionOutput=class YolosObjectDetectionOutput extends ModelOutput{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}};let SamPreTrainedModel=class SamPreTrainedModel extends PreTrainedModel{};let SamModel=class SamModel extends SamPreTrainedModel{async _call(e){return new SamImageSegmentationOutput(await super._call(e))}};let SamImageSegmentationOutput=class SamImageSegmentationOutput extends ModelOutput{constructor({iou_scores:e,pred_masks:t}){super(),this.iou_scores=e,this.pred_masks=t}};let MarianPreTrainedModel=class MarianPreTrainedModel extends PreTrainedModel{};let M2M100PreTrainedModel=class M2M100PreTrainedModel extends PreTrainedModel{};let Wav2Vec2PreTrainedModel=class Wav2Vec2PreTrainedModel extends PreTrainedModel{};let WavLMPreTrainedModel=class WavLMPreTrainedModel extends PreTrainedModel{};let SpeechT5PreTrainedModel=class SpeechT5PreTrainedModel extends PreTrainedModel{};let PretrainedMixin=class PretrainedMixin{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{quantized:t=!0,progress_callback:n=null,config:r=null,cache_dir:o=null,local_files_only:a=!1,revision:i="main",model_file_name:d=null}={}){let l={quantized:t,progress_callback:n,config:r,cache_dir:o,local_files_only:a,revision:i,model_file_name:d};if(r=await s.z.from_pretrained(e,l),l.config||(l.config=r),!this.MODEL_CLASS_MAPPINGS)throw Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);for(let t of this.MODEL_CLASS_MAPPINGS){let n=t.get(r.model_type);if(n)return await n[1].from_pretrained(e,l)}if(this.BASE_IF_FAIL)return console.warn(`Unknown model class "${r.model_type}", attempting to construct from base class.`),await PreTrainedModel.from_pretrained(e,l);throw Error(`Unsupported model type: ${r.model_type}`)}};let p=new Map([["bert",["BertModel",class extends BertPreTrainedModel{}]],["camembert",["CamembertModel",class extends CamembertPreTrainedModel{}]],["deberta",["DebertaModel",class extends DebertaPreTrainedModel{}]],["deberta-v2",["DebertaV2Model",class extends DebertaV2PreTrainedModel{}]],["mpnet",["MPNetModel",class extends MPNetPreTrainedModel{}]],["albert",["AlbertModel",class extends AlbertPreTrainedModel{}]],["distilbert",["DistilBertModel",class extends DistilBertPreTrainedModel{}]],["roberta",["RobertaModel",class extends RobertaPreTrainedModel{}]],["xlm",["XLMModel",class extends XLMPreTrainedModel{}]],["xlm-roberta",["XLMRobertaModel",class extends XLMRobertaPreTrainedModel{}]],["clip",["CLIPModel",class extends CLIPPreTrainedModel{}]],["mobilebert",["MobileBertModel",class extends MobileBertPreTrainedModel{}]],["squeezebert",["SqueezeBertModel",class extends SqueezeBertPreTrainedModel{}]],["wav2vec2",["Wav2Vec2Model",class extends Wav2Vec2PreTrainedModel{}]],["wavlm",["WavLMModel",class extends WavLMPreTrainedModel{}]],["detr",["DetrModel",class extends DetrPreTrainedModel{}]],["vit",["ViTModel",class extends ViTPreTrainedModel{}]],["mobilevit",["MobileViTModel",class extends MobileViTPreTrainedModel{}]],["beit",["BeitModel",class extends BeitPreTrainedModel{}]],["deit",["DeiTModel",class extends DeiTPreTrainedModel{}]],["resnet",["ResNetModel",class extends ResNetPreTrainedModel{}]],["swin",["SwinModel",class extends SwinPreTrainedModel{}]],["donut-swin",["DonutSwinModel",class extends DonutSwinPreTrainedModel{}]],["yolos",["YolosModel",class extends YolosPreTrainedModel{}]],["hifigan",["SpeechT5HifiGan",class extends PreTrainedModel{main_input_name="spectrogram"}]],["sam",["SamModel",SamModel]]]),f=new Map([["t5",["T5Model",class extends T5PreTrainedModel{}]],["longt5",["LongT5Model",class extends LongT5PreTrainedModel{}]],["mt5",["MT5Model",class extends MT5PreTrainedModel{}]],["bart",["BartModel",class extends BartPretrainedModel{}]],["mbart",["MBartModel",class extends MBartPreTrainedModel{}]],["marian",["MarianModel",class extends MarianPreTrainedModel{}]],["whisper",["WhisperModel",class extends WhisperPreTrainedModel{}]],["m2m_100",["M2M100Model",class extends M2M100PreTrainedModel{}]],["blenderbot",["BlenderbotModel",class extends BlenderbotPreTrainedModel{}]],["blenderbot-small",["BlenderbotSmallModel",class extends BlenderbotSmallPreTrainedModel{}]]]),g=new Map([["bloom",["BloomModel",class extends BloomPreTrainedModel{}]],["gpt2",["GPT2Model",class extends GPT2PreTrainedModel{}]],["gptj",["GPTJModel",class extends GPTJPreTrainedModel{}]],["gpt_bigcode",["GPTBigCodeModel",class extends GPTBigCodePreTrainedModel{}]],["gpt_neo",["GPTNeoModel",class extends GPTNeoPreTrainedModel{}]],["gpt_neox",["GPTNeoXModel",class extends GPTNeoXPreTrainedModel{}]],["codegen",["CodeGenModel",class extends CodeGenPreTrainedModel{}]],["llama",["LlamaModel",class extends LlamaPreTrainedModel{}]],["mpt",["MptModel",class extends MptPreTrainedModel{}]],["opt",["OPTModel",class extends OPTPreTrainedModel{}]]]),P=new Map([["speecht5",["SpeechT5ForSpeechToText",class extends SpeechT5PreTrainedModel{}]],["whisper",["WhisperForConditionalGeneration",class extends WhisperPreTrainedModel{requires_attention_mask=!1;main_input_name="input_features";constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}async generate(e,t=null,n=null){if(t=this._get_generation_config(t),t.return_timestamps??=!1,t.return_timestamps&&(n=[new a.Pg(t)]),t.return_token_timestamps&&(t.output_attentions=!0,t.return_dict_in_generate=!0,"translate"===t.task&&console.warn("Token-level timestamps may not be reliable for task 'translate'."),!t.alignment_heads))throw Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");let s=await super.generate(e,t,n);return t.return_token_timestamps&&t.alignment_heads&&(s.token_timestamps=this._extract_token_timestamps(s,t.alignment_heads,t.num_frames)),s}_extract_token_timestamps(e,t,n=null,s=.02){if(!e.cross_attentions)throw Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");let o=this.config.median_filter_width;void 0===o&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),o=7);let a=e.cross_attentions.map(e=>{let s=Array.from({length:this.config.decoder_layers},(t,n)=>(0,i.d3)(e.map(e=>e[n]),2)),r=(0,i.kn)(t.map(([e,t])=>n?s[e].slice(null,t,null,[0,n]):s[e].slice(null,t)));r=r.transpose(1,0,2,3);let[a,d]=(0,i.f3)(r,-2,0,!0),c=r.clone();for(let e=0;e<c.dims[0];++e){let t=c[e];for(let n=0;n<t.dims[0];++n){let s=t[n],r=a[e][n][0],i=d[e][n][0];for(let e=0;e<s.dims[0];++e){let t=s[e];for(let e=0;e<t.data.length;++e)t.data[e]=(t.data[e]-i.data[e])/r.data[e];t.data.set((0,l.qCb)(t.data,o))}}}let u=(0,i.J6)(c,1);return u}),d=[e.sequences.length,e.sequences[0].length],c=new i.es("float32",new Float32Array(d[0]*d[1]),d);for(let e=0;e<d[0];++e){let t=a[e].neg().squeeze_(0),[n,o]=(0,i.Ks)(t),d=Array.from({length:n.length-1},(e,t)=>n[t+1]-n[t]),l=(0,r.eG)([1],d).map(e=>!!e),u=[];for(let e=0;e<l.length;++e)l[e]&&u.push(o[e]*s);c[e].data.set(u,1)}return c}}]]]),T=new Map([["speecht5",["SpeechT5ForTextToSpeech",class extends SpeechT5PreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.hidden_size/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.hidden_size/this.num_encoder_heads}async generate_speech(e,t,{threshold:n=.5,minlenratio:s=0,maxlenratio:r=20,vocoder:o=null}={}){let{encoder_outputs:a,encoder_attention_mask:d}=await encoderForward(this,{input_ids:e}),l=a.dims[1]/this.config.reduction_factor,c=Math.floor(l*r),u=Math.floor(l*s),_=this.config.num_mel_bins,h=[],m=null,M=null,p=0;for(;;){++p;let e=boolTensor(!!M),s={use_cache_branch:e,output_sequence:M?M.output_sequence_out:new i.es("float32",new Float32Array(_),[1,1,_]),encoder_attention_mask:d,speaker_embeddings:t,encoder_hidden_states:a};this.addPastKeyValues(s,m),M=await sessionRun(this.decoder_merged_session,s),m=this.getPastKeyValues(M,m);let{prob:r,spectrum:o}=M;if(h.push(o),p>=u&&(Array.from(r.data).filter(e=>e>=n).length>0||p>=c))break}let f=(0,i.d3)(h),{waveform:g}=await sessionRun(o.session,{spectrogram:f});return{spectrogram:f,waveform:g}}}]]]),w=new Map([["bert",["BertForSequenceClassification",class extends BertPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["camembert",["CamembertForSequenceClassification",class extends CamembertPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["deberta",["DebertaForSequenceClassification",class extends DebertaPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["deberta-v2",["DebertaV2ForSequenceClassification",class extends DebertaV2PreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["mpnet",["MPNetForSequenceClassification",class extends MPNetPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["albert",["AlbertForSequenceClassification",class extends AlbertPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["distilbert",["DistilBertForSequenceClassification",class extends DistilBertPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["roberta",["RobertaForSequenceClassification",class extends RobertaPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["xlm",["XLMForSequenceClassification",class extends XLMPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["xlm-roberta",["XLMRobertaForSequenceClassification",class extends XLMRobertaPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["bart",["BartForSequenceClassification",class extends BartPretrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["mbart",["MBartForSequenceClassification",class extends MBartPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["mobilebert",["MobileBertForSequenceClassification",class extends MobileBertPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["squeezebert",["SqueezeBertForSequenceClassification",class extends SqueezeBertPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]]]),y=new Map([["bert",["BertForTokenClassification",class extends BertPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["camembert",["CamembertForTokenClassification",class extends CamembertPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["deberta",["DebertaForTokenClassification",class extends DebertaPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["deberta-v2",["DebertaV2ForTokenClassification",class extends DebertaV2PreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["mpnet",["MPNetForTokenClassification",class extends MPNetPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["distilbert",["DistilBertForTokenClassification",class extends DistilBertPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["roberta",["RobertaForTokenClassification",class extends RobertaPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["xlm",["XLMForTokenClassification",class extends XLMPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]],["xlm-roberta",["XLMRobertaForTokenClassification",class extends XLMRobertaPreTrainedModel{async _call(e){return new TokenClassifierOutput(await super._call(e))}}]]]),x=new Map([["t5",["T5ForConditionalGeneration",class extends T5PreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}]],["longt5",["LongT5ForConditionalGeneration",class extends LongT5PreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}]],["mt5",["MT5ForConditionalGeneration",class extends MT5PreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}]],["bart",["BartForConditionalGeneration",class extends BartPretrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]],["mbart",["MBartForConditionalGeneration",class extends MBartPreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]],["marian",["MarianMTModel",class extends MarianPreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]],["m2m_100",["M2M100ForConditionalGeneration",class extends M2M100PreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]],["blenderbot",["BlenderbotForConditionalGeneration",class extends BlenderbotPreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",class extends BlenderbotSmallPreTrainedModel{constructor(e,t,n,s){super(e,t),this.decoder_merged_session=n,this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]]]),b=new Map([["bloom",["BloomForCausalLM",class extends BloomPreTrainedModel{}]],["gpt2",["GPT2LMHeadModel",class extends GPT2PreTrainedModel{}]],["gptj",["GPTJForCausalLM",class extends GPTJPreTrainedModel{}]],["gpt_bigcode",["GPTBigCodeForCausalLM",class extends GPTBigCodePreTrainedModel{}]],["gpt_neo",["GPTNeoForCausalLM",class extends GPTNeoPreTrainedModel{}]],["gpt_neox",["GPTNeoXForCausalLM",class extends GPTNeoXPreTrainedModel{}]],["codegen",["CodeGenForCausalLM",class extends CodeGenPreTrainedModel{}]],["llama",["LlamaForCausalLM",class extends LlamaPreTrainedModel{}]],["mpt",["MptForCausalLM",class extends MptPreTrainedModel{}]],["opt",["OPTForCausalLM",class extends OPTPreTrainedModel{}]],["mbart",["MBartForCausalLM",class extends MBartPreTrainedModel{constructor(e,t,n){super(e,t),this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}]]]),k=new Map([["bert",["BertForMaskedLM",class extends BertPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["camembert",["CamembertForMaskedLM",class extends CamembertPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["deberta",["DebertaForMaskedLM",class extends DebertaPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["deberta-v2",["DebertaV2ForMaskedLM",class extends DebertaV2PreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["mpnet",["MPNetForMaskedLM",class extends MPNetPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["albert",["AlbertForMaskedLM",class extends AlbertPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["distilbert",["DistilBertForMaskedLM",class extends DistilBertPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["roberta",["RobertaForMaskedLM",class extends RobertaPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["xlm",["XLMWithLMHeadModel",class extends XLMPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["xlm-roberta",["XLMRobertaForMaskedLM",class extends XLMRobertaPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["mobilebert",["MobileBertForMaskedLM",class extends MobileBertPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]],["squeezebert",["SqueezeBertForMaskedLM",class extends SqueezeBertPreTrainedModel{async _call(e){return new MaskedLMOutput(await super._call(e))}}]]]),S=new Map([["bert",["BertForQuestionAnswering",class extends BertPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["camembert",["CamembertForQuestionAnswering",class extends CamembertPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["deberta",["DebertaForQuestionAnswering",class extends DebertaPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["deberta-v2",["DebertaV2ForQuestionAnswering",class extends DebertaV2PreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["mpnet",["MPNetForQuestionAnswering",class extends MPNetPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["albert",["AlbertForQuestionAnswering",class extends AlbertPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["distilbert",["DistilBertForQuestionAnswering",class extends DistilBertPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["roberta",["RobertaForQuestionAnswering",class extends RobertaPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["xlm",["XLMForQuestionAnswering",class extends XLMPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["xlm-roberta",["XLMRobertaForQuestionAnswering",class extends XLMRobertaPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["mobilebert",["MobileBertForQuestionAnswering",class extends MobileBertPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]],["squeezebert",["SqueezeBertForQuestionAnswering",class extends SqueezeBertPreTrainedModel{async _call(e){return new QuestionAnsweringModelOutput(await super._call(e))}}]]]),C=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",VisionEncoderDecoderModel]]]),A=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",VisionEncoderDecoderModel]]]),O=new Map([["vit",["ViTForImageClassification",class extends ViTPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["mobilevit",["MobileViTForImageClassification",class extends MobileViTPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["beit",["BeitForImageClassification",class extends BeitPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["deit",["DeiTForImageClassification",class extends DeiTPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["resnet",["ResNetForImageClassification",class extends ResNetPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["swin",["SwinForImageClassification",class extends SwinPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]]]),v=new Map([["detr",["DetrForObjectDetection",class extends DetrPreTrainedModel{async _call(e){return new DetrObjectDetectionOutput(await super._call(e))}}]],["yolos",["YolosForObjectDetection",class extends YolosPreTrainedModel{async _call(e){return new YolosObjectDetectionOutput(await super._call(e))}}]]]),L=new Map([["detr",["DetrForSegmentation",class extends DetrPreTrainedModel{async _call(e){return new DetrSegmentationOutput(await super._call(e))}}]]]),F=new Map([["sam",["SamModel",SamModel]]]),B=new Map([["wav2vec2",["Wav2Vec2ForCTC",class extends Wav2Vec2PreTrainedModel{async _call(e){return new CausalLMOutput(await super._call(e))}}]],["wavlm",["WavLMForCTC",class extends WavLMPreTrainedModel{async _call(e){return new CausalLMOutput(await super._call(e))}}]]]),q=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",class extends Wav2Vec2PreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]],["wavlm",["WavLMForSequenceClassification",class extends WavLMPreTrainedModel{async _call(e){return new SequenceClassifierOutput(await super._call(e))}}]]]),D=[[p,_.EncoderOnly],[f,_.EncoderDecoder],[g,_.DecoderOnly],[w,_.EncoderOnly],[y,_.EncoderOnly],[x,_.Seq2Seq],[P,_.Seq2Seq],[b,_.DecoderOnly],[k,_.EncoderOnly],[S,_.EncoderOnly],[C,_.Vision2Seq],[O,_.EncoderOnly],[L,_.EncoderOnly],[v,_.EncoderOnly],[F,_.EncoderOnly],[B,_.EncoderOnly],[q,_.EncoderOnly],[T,_.Seq2Seq]];for(let[e,t]of D)for(let[n,s]of e.values())h.set(n,t),M.set(s,n),m.set(n,s);let E=[["CLIPTextModelWithProjection",class extends CLIPPreTrainedModel{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}},_.EncoderOnly],["CLIPVisionModelWithProjection",class extends CLIPPreTrainedModel{static async from_pretrained(e,t={}){return t.model_file_name??="vision_model",super.from_pretrained(e,t)}},_.EncoderOnly]];for(let[e,t,n]of E)h.set(e,n),M.set(t,e),m.set(e,t);let AutoModel=class AutoModel extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[p,f,g];static BASE_IF_FAIL=!0};let AutoModelForSequenceClassification=class AutoModelForSequenceClassification extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[w]};let AutoModelForTokenClassification=class AutoModelForTokenClassification extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[y]};let AutoModelForSeq2SeqLM=class AutoModelForSeq2SeqLM extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[x]};let AutoModelForSpeechSeq2Seq=class AutoModelForSpeechSeq2Seq extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[P]};let AutoModelForTextToSpectrogram=class AutoModelForTextToSpectrogram extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[T]};let AutoModelForCausalLM=class AutoModelForCausalLM extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[b]};let AutoModelForMaskedLM=class AutoModelForMaskedLM extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[k]};let AutoModelForQuestionAnswering=class AutoModelForQuestionAnswering extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[S]};let AutoModelForVision2Seq=class AutoModelForVision2Seq extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[C]};let AutoModelForImageClassification=class AutoModelForImageClassification extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[O]};let AutoModelForImageSegmentation=class AutoModelForImageSegmentation extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[L]};let AutoModelForObjectDetection=class AutoModelForObjectDetection extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[v]};let AutoModelForCTC=class AutoModelForCTC extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[B]};let AutoModelForAudioClassification=class AutoModelForAudioClassification extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[q]};let AutoModelForDocumentQuestionAnswering=class AutoModelForDocumentQuestionAnswering extends PretrainedMixin{static MODEL_CLASS_MAPPINGS=[A]};let Seq2SeqLMOutput=class Seq2SeqLMOutput extends ModelOutput{constructor({logits:e,past_key_values:t,encoder_outputs:n,decoder_attentions:s=null,cross_attentions:r=null}){super(),this.logits=e,this.past_key_values=t,this.encoder_outputs=n,this.decoder_attentions=s,this.cross_attentions=r}};let SequenceClassifierOutput=class SequenceClassifierOutput extends ModelOutput{constructor({logits:e}){super(),this.logits=e}};let TokenClassifierOutput=class TokenClassifierOutput extends ModelOutput{constructor({logits:e}){super(),this.logits=e}};let MaskedLMOutput=class MaskedLMOutput extends ModelOutput{constructor({logits:e}){super(),this.logits=e}};let QuestionAnsweringModelOutput=class QuestionAnsweringModelOutput extends ModelOutput{constructor({start_logits:e,end_logits:t}){super(),this.start_logits=e,this.end_logits=t}};let CausalLMOutput=class CausalLMOutput extends ModelOutput{constructor({logits:e}){super(),this.logits=e}}}}]);